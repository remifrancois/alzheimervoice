{
  "nav": {
    "science": "Science",
    "technology": "Technology",
    "families": "For Families",
    "cta": "Family Access",
    "scientific": "Science Research",
    "family": "For Family",
    "opensource": "Open Source",
    "cvf": "CVF Engine",
    "compliance": "Compliance",
    "creators": "Creators"
  },
  "hero": {
    "badge": "Cerebral Valley x Anthropic Hackathon 2026",
    "title1": "Detecting Alzheimer's",
    "title2": "Through Voice",
    "subtitle": "The world's first Cognitive Voice Fingerprint engine. AlzheimerVoice identifies subtle linguistic drift years before clinical diagnosis \u2014 through natural conversation analysis powered by Claude AI.",
    "ctaPrimary": "Start Monitoring",
    "ctaSecondary": "Read the Science",
    "vizStatus": "Analyzing voice patterns...",
    "scroll": "Scroll to explore",
    "domainLexical": "Lexical",
    "domainSyntactic": "Syntactic",
    "domainCoherence": "Coherence",
    "domainFluency": "Fluency",
    "domainMemory": "Memory"
  },
  "stats": {
    "dementiaLabel": "People living with dementia worldwide",
    "dementiaSource": "WHO 2023",
    "markersLabel": "Linguistic markers precede clinical diagnosis",
    "markersSource": "Fraser 2016",
    "dimensionsLabel": "Cognitive dimensions analyzed per session",
    "dimensionsSource": "CVF Engine",
    "domainsLabel": "Linguistic domains continuously monitored",
    "domainsSource": "AlzheimerVoice"
  },
  "problem": {
    "label": "The Challenge",
    "title": "The Silent",
    "titleHighlight": "Progression",
    "p1": "Alzheimer\u2019s disease begins its assault on the brain <strong>up to 20 years before the first clinical symptom</strong>. By the time a patient receives a diagnosis, significant and irreversible neurodegeneration has already occurred.",
    "p2": "Current diagnostic methods \u2014 cognitive tests, brain imaging, cerebrospinal fluid analysis \u2014 are expensive, invasive, and typically only deployed after noticeable symptoms emerge. <strong>The average diagnosis comes 2\u20133 years after symptom onset.</strong>",
    "p3": "But research has revealed a crucial window: <strong>linguistic patterns begin to change years before other symptoms appear</strong>. These subtle shifts in how we speak \u2014 word choices, sentence structures, coherence patterns \u2014 are invisible to the human ear but detectable by AI.",
    "detection": "AlzheimerVoice detects here",
    "stage1Year": "Years -10 to -5",
    "stage1Title": "Subtle Linguistic Shifts",
    "stage1Desc": "Word-finding difficulties, reduced vocabulary diversity, simpler sentence structures begin to emerge in natural speech.",
    "stage2Year": "Years -5 to -2",
    "stage2Title": "Measurable Cognitive Drift",
    "stage2Desc": "Semantic coherence declines, speech fluency changes, memory-dependent recall weakens across multiple domains.",
    "stage3Year": "Years -2 to 0",
    "stage3Title": "Noticeable Symptoms",
    "stage3Desc": "Family and friends begin to notice changes. Traditional cognitive tests start to show decline. Neurodegeneration accelerates.",
    "stage4Year": "Year 0+",
    "stage4Title": "Clinical Diagnosis",
    "stage4Desc": "Formal diagnosis is made. Significant irreversible neurodegeneration already present. Treatment options are limited."
  },
  "breakthrough": {
    "label": "The Breakthrough",
    "title": "A World First in",
    "titleHighlight": "Cognitive Monitoring",
    "subtitle": "AlzheimerVoice introduces the Cognitive Voice Fingerprint \u2014 a revolutionary approach to detecting Alzheimer\u2019s through the subtle patterns hidden in everyday speech.",
    "feature1Title": "Cognitive Voice Fingerprint",
    "feature1Desc": "A unique 85-indicator vector capturing the complete linguistic and acoustic profile of each individual across 9 cognitive domains, creating a deeply personal cognitive baseline.",
    "feature2Title": "Individual Baseline Drift",
    "feature2Desc": "Rather than comparing against population norms, AlzheimerVoice measures each person against their own established baseline \u2014 detecting personal cognitive changes with precision.",
    "feature3Title": "Non-Invasive Monitoring",
    "feature3Desc": "Through natural conversation \u2014 no blood draws, no brain scans, no clinical visits. Just regular phone or video calls analyzed in real-time by advanced AI.",
    "feature4Title": "Confounder-Adjusted",
    "feature4Desc": "Illness, poor sleep, medication changes, and emotional distress are automatically factored in \u2014 reducing false positives and increasing clinical reliability."
  },
  "howItWorks": {
    "label": "How It Works",
    "title": "From Conversation to",
    "titleHighlight": "Early Detection",
    "subtitle": "Four simple steps that could change everything for your family.",
    "step1Title": "Regular Conversations",
    "step1Desc": "Natural phone or video calls with your loved one. No special equipment, no clinical setting \u2014 just everyday conversation.",
    "step2Title": "AI Feature Extraction",
    "step2Desc": "Claude AI analyzes speech in real-time via two streams \u2014 acoustic signal processing and linguistic analysis \u2014 extracting 85 cognitive indicators across nine domains.",
    "step3Title": "Baseline Comparison",
    "step3Desc": "Each session is compared against the individual\u2019s personal cognitive baseline, detecting drift that population-level tests would miss.",
    "step4Title": "Clinical Alerts",
    "step4Desc": "A four-tier graduated alert system notifies clinicians and families of any significant cognitive drift, with detailed weekly narrative reports."
  },
  "science": {
    "label": "Scientific Foundation",
    "title": "Built on",
    "titleHighlight": "Decades of Research",
    "subtitle": "AlzheimerVoice\u2019s approach is grounded in peer-reviewed research from leading institutions in computational linguistics and neurodegenerative disease.",
    "paper1Highlight": "81.92% accuracy",
    "paper1Finding": "Achieved 81.92% classification accuracy using linguistic features extracted from speech transcripts of the DementiaBank Pitt corpus, establishing that computational linguistic analysis can reliably detect AD.",
    "paper2Highlight": "Tracks progression",
    "paper2Finding": "Demonstrated that connected speech analysis can track disease progression over time, with linguistic measures correlating directly with neuropathological severity at autopsy.",
    "paper3Highlight": "Pre-dementia detection",
    "paper3Finding": "Showed that automatic speech analysis can distinguish between healthy controls, MCI, and AD patients with high sensitivity and specificity \u2014 even at the pre-dementia stage.",
    "paper4Highlight": "Speech-only viable",
    "paper4Finding": "The ADReSS challenge established rigorous benchmarks for detecting Alzheimer\u2019s from speech, demonstrating the viability of speech-only cognitive assessment across multiple research teams.",
    "cascadeTitle": "AD Linguistic Cascade Model",
    "cascadeSubtitle": "Based on Fraser 2016 taxonomy \u2014 tracking progressive linguistic deterioration stages",
    "cascade1Name": "Pre-symptomatic",
    "cascade1Desc": "Fluency micro-changes",
    "cascade2Name": "Semantic Memory",
    "cascade2Desc": "Lexical + coherence decline",
    "cascade3Name": "Syntactic Simplification",
    "cascade3Desc": "Grammar complexity reduction",
    "cascade4Name": "Discourse Collapse",
    "cascade4Desc": "Global coherence breakdown"
  },
  "domains": {
    "label": "Nine Domains",
    "title": "85 Indicators Across",
    "titleHighlight": "9 Cognitive Domains",
    "subtitle": "Each conversation is analyzed across nine scientifically validated domains \u2014 seven linguistic plus two acoustic \u2014 using a two-stream architecture that combines text and audio analysis.",
    "lexicalName": "Lexical Richness",
    "lexicalDesc": "Vocabulary diversity, word frequency distribution, and type-token ratios. Among the earliest markers to show decline in Alzheimer\u2019s progression.",
    "syntacticName": "Syntactic Complexity",
    "syntacticDesc": "Sentence structure, clause embedding depth, and grammatical sophistication. Simplification patterns indicate disease progression.",
    "coherenceName": "Semantic Coherence",
    "coherenceDesc": "Topic consistency, propositional density, and logical flow between utterances. Critical for tracking semantic memory decline.",
    "fluencyName": "Speech Fluency",
    "fluencyDesc": "Pause patterns, filler words, repetitions, and speech rate. Often the first domain to show pre-symptomatic changes detectable by AI.",
    "memoryName": "Memory Recall",
    "memoryDesc": "Narrative completeness, temporal ordering, and detail retention. Directly reflects episodic and working memory function.",
    "discourseName": "Discourse & Pragmatics",
    "discourseDesc": "Narrative structure, self-correction patterns, and conversational awareness. Self-correction loss is a unique metacognitive marker of AD.",
    "affectiveName": "Affective & Mood",
    "affectiveDesc": "Emotional valence, self-focus, and engagement patterns. Critical for differentiating depression from cognitive decline.",
    "acousticName": "Acoustic Features",
    "acousticDesc": "Voice signal characteristics including pitch, jitter, shimmer, and spectral features. The strongest cross-cultural depression markers and key PD indicators.",
    "pdMotorName": "PD Motor Speech",
    "pdMotorDesc": "Nonlinear dynamics and articulatory features specific to Parkinson\u2019s disease. The PPE+RPDE+DFA+HNR quartet achieves 91.4% PD detection accuracy.",
    "compositeTitle": "Composite Z-Score",
    "compositeDesc": "All 85 indicators combine into a weighted composite z-score measuring overall cognitive drift from the individual\u2019s established baseline."
  },
  "technology": {
    "label": "The Technology",
    "title": "Powered by",
    "titleHighlight": "Claude AI",
    "p1": "AlzheimerVoice leverages <strong>Claude Opus 4.6</strong> by Anthropic \u2014 one of the most advanced language models ever built \u2014 for both real-time feature extraction and deep clinical analysis.",
    "p2": "Using Claude\u2019s <strong>extended thinking capability</strong>, the system performs thorough clinical reasoning for weekly reports, considering the full context of a patient\u2019s linguistic trajectory, confounding factors, and domain-specific patterns.",
    "p3": "The result is a level of linguistic analysis that approaches \u2014 and in some dimensions surpasses \u2014 what human clinical linguists can achieve, delivered continuously and at scale.",
    "specModel": "Analysis Model",
    "specThinking": "Thinking Budget",
    "specFeatures": "Indicators / Session",
    "specProcessing": "Processing",
    "specModelVal": "Claude Opus 4.6",
    "specThinkingVal": "16,000 tokens",
    "specFeaturesVal": "85 indicators",
    "specProcessingVal": "Real-time",
    "pipelineTitle": "Processing Pipeline",
    "pipe1Label": "Voice Input",
    "pipe1Sub": "Natural conversation recording",
    "pipe2Label": "Claude Sonnet 4.5",
    "pipe2Sub": "Daily text extraction (64 linguistic indicators)",
    "pipe3Label": "Audio Pipeline",
    "pipe3Sub": "Acoustic pipeline (parselmouth + librosa + nolds)",
    "pipe4Label": "V5 Scoring Engine",
    "pipe4Sub": "9-domain scoring, 35-rule differential, 3 cascades",
    "pipe5Label": "Claude Opus 4.6",
    "pipe5Sub": "Weekly deep analysis + clinical reports"
  },
  "families": {
    "label": "For Families",
    "title": "For the People Who",
    "titleHighlight": "Care Most",
    "subtitle": "We built AlzheimerVoice for families who want to protect their loved ones. Because the best time to act is before you notice something is wrong.",
    "benefit1Title": "Peace of Mind",
    "benefit1Desc": "Continuous monitoring means you\u2019ll know about cognitive changes as early as possible \u2014 not months or years after they begin.",
    "benefit2Title": "Simple Weekly Reports",
    "benefit2Desc": "Clear, jargon-free reports written for families. Understand your loved one\u2019s cognitive health without a medical degree.",
    "benefit3Title": "Natural & Dignified",
    "benefit3Desc": "No clinical tests, no uncomfortable procedures. Just regular conversations \u2014 preserving your loved one\u2019s dignity and comfort.",
    "benefit4Title": "More Time to Plan",
    "benefit4Desc": "Early detection gives families critical time for care planning, treatment exploration, legal preparations, and meaningful time together.",
    "quote": "\u201CIf we had known earlier, we would have had more time. More conversations. More moments. That\u2019s what early detection gives you \u2014 <strong>time</strong>.\u201D",
    "quoteAttribution": "\u2014 The motivation behind AlzheimerVoice"
  },
  "modes": {
    "label": "Two Modes",
    "title": "Prevention &",
    "titleHighlight": "Treatment",
    "subtitle": "AlzheimerVoice adapts to where your loved one is on their journey \u2014 whether you\u2019re watching for early signs or supporting someone already diagnosed.",
    "preventionTag": "Prevention Mode",
    "preventionTitle": "Families Share Memories, AI Leads the Conversation",
    "preventionDesc": "You provide the memories \u2014 childhood stories, favorite holidays, career milestones, family traditions. AlzheimerVoice\u2019s AI weaves them into warm, natural phone conversations with your loved one.",
    "preventionHow": "How it works",
    "preventionStep1": "Families upload memories: stories, names, places, life events",
    "preventionStep2": "AI crafts personalized conversation topics from those memories",
    "preventionStep3": "Regular phone calls feel natural \u2014 your loved one enjoys reminiscing",
    "preventionStep4": "While talking, the CVF Engine silently analyzes 85 cognitive indicators across audio and text",
    "preventionStep5": "Families receive weekly cognitive drift reports",
    "preventionKey": "Your loved one never feels tested. They simply enjoy a conversation about their own life \u2014 while AlzheimerVoice watches for the earliest signs of cognitive change.",
    "treatmentTag": "Treatment Mode",
    "treatmentTitle": "Memory Activation Therapy for Diagnosed Patients",
    "treatmentDesc": "For people already diagnosed with Alzheimer\u2019s or MCI, AlzheimerVoice becomes a therapeutic tool. AI-guided phone calls use personal memories to actively stimulate cognitive pathways and slow decline.",
    "treatmentHow": "Therapeutic approach",
    "treatmentStep1": "Structured reminiscence sessions built around the patient\u2019s life story",
    "treatmentStep2": "AI progressively guides recall from strong memories to weaker ones",
    "treatmentStep3": "Repeated memory activation strengthens neural connections",
    "treatmentStep4": "Sessions adapt in real-time to the patient\u2019s cognitive state",
    "treatmentStep5": "Clinicians receive detailed session reports tracking response patterns",
    "treatmentKey": "Research shows that regular reminiscence therapy can improve mood, reduce agitation, and help maintain cognitive function. AlzheimerVoice delivers this at scale \u2014 personalized to each patient\u2019s unique life history.",
    "scienceBasis": "Scientific Basis",
    "sciencePoint1": "<strong>Reminiscence therapy</strong> is recognized by the Cochrane Collaboration as beneficial for mood and cognition in dementia patients",
    "sciencePoint2": "<strong>Autobiographical memory stimulation</strong> activates the medial temporal lobe and prefrontal cortex \u2014 regions affected earliest by Alzheimer\u2019s",
    "sciencePoint3": "<strong>Regular cognitive engagement</strong> through meaningful conversation contributes to cognitive reserve and may delay functional decline"
  },
  "cta": {
    "title1": "Start Protecting Your",
    "title2": "Loved Ones Today",
    "subtitle": "AlzheimerVoice is fully open source. Explore the Cognitive Voice Fingerprint engine on GitHub, fork it, and build your own cognitive monitoring tools.",
    "primary": "Open Source on GitHub",
    "secondary": "Discover how it was built"
  },
  "footer": {
    "brandDesc": "Cognitive Voice Fingerprint Engine for early Alzheimer\u2019s detection through linguistic analysis. Open source, privacy-first, built for families.",
    "researchHeader": "Research",
    "linkScience": "Scientific Foundation",
    "linkCvf": "CVF Engine V5",
    "linkOpenSource": "Open Source",
    "familyHeader": "For Families",
    "linkFamily": "Family Guide",
    "linkDemo": "Hackathon Demo",
    "linkPlatform": "Family Access",
    "legalHeader": "Legal & Trust",
    "linkPrivacy": "Privacy & HIPAA",
    "linkCompliance": "Compliance",
    "linkLegal": "Legal & Licensing",
    "linkCreators": "Meet the Creators",
    "bottomLine": "Alzheimer Cognitive Voice Fingerprint Engine V5 \u2014 Built at the Cerebral Valley x Anthropic Hackathon, February 2026",
    "disclaimer": "For research and demonstration purposes. Not a medical device.",
    "affiliation": "AlzheimerVoice is not affiliated with Anthropic, Claude, Cerebral Valley, or any other organization, website, or research paper mentioned on this site. All trademarks belong to their respective owners."
  },
  "scientific": {
    "heroTitle": "The Science Behind",
    "heroHighlight": "AlzheimerVoice",
    "heroSubtitle": "A deep dive into the Cognitive Voice Fingerprint engine, the 85-indicator two-stream analysis framework, and the clinical research that makes early detection of Alzheimer\u2019s, Parkinson\u2019s, and depression through voice possible.",
    "engineLabel": "CVF Engine",
    "engineTitle": "Cognitive Voice Fingerprint",
    "engineHighlight": "Engine Architecture",
    "engineDesc": "The CVF Engine V5 is a dual-pass evidence-compiled architecture. Pass 1 (Real-Time): Claude Sonnet 4.5 + acoustic pipeline extract 85 indicators via parallel audio and text streams. Pass 2 (Deep Reasoning): Claude Opus 4.6 with extended thinking performs weekly clinical analysis. Built from 80 research papers across AD, PD, and depression.",
    "pipelineTitle": "Processing Pipeline",
    "pipe1Title": "Audio Ingestion",
    "pipe1Desc": "Voice input is captured via standard phone or video calls. The audio stream is segmented and prepared for transcription with noise filtering and speaker diarization.",
    "pipe2Title": "Transcription & Normalization",
    "pipe2Desc": "Speech-to-text conversion produces a clean transcript. Text is normalized for filler removal, false starts, and cross-talk elimination while preserving diagnostically relevant disfluencies.",
    "pipe3Title": "Claude Sonnet Feature Extraction",
    "pipe3Desc": "Claude Sonnet 4.5 analyzes the transcript daily, extracting 64 linguistic indicators across 7 text domains. Each indicator is scored using clinically-grounded rubrics compiled from 80 research papers.",
    "pipe4Title": "Baseline Comparison & Drift Detection",
    "pipe4Desc": "Current session scores are compared against the individual\u2019s 14-21 session rolling baseline using z-score normalization. The engine runs 35-rule differential diagnosis across 8 conditions and detects 3 cascade types.",
    "pipe5Title": "Weekly Opus Deep Analysis",
    "pipe5Desc": "Claude Opus 4.6 with extended thinking (20K token budget) performs weekly clinical reasoning \u2014 cross-validating differential, discovering micro-patterns, generating reports, and designing next week\u2019s probes.",
    "dimensionsLabel": "85 Indicators",
    "dimensionsTitle": "85 Evidence-Based",
    "dimensionsHighlight": "Cognitive Indicators",
    "dimensionsDesc": "Each conversation produces an 85-element vector spanning nine domains (seven linguistic + two acoustic). Every indicator was selected based on peer-reviewed research identifying the most sensitive markers of cognitive decline, weighted by evidence strength from 80 research papers.",
    "domainLexical": "Lexical Richness (15% weight \u2014 17 indicators)",
    "lexical1": "Type-Token Ratio (TTR)",
    "lexical1Desc": "Vocabulary diversity \u2014 ratio of unique words to total words. Declining TTR is among the earliest detectable markers of Alzheimer's (effect size 1.0).",
    "lexical2": "Brunet's Index",
    "lexical2Desc": "Length-independent lexical richness measure. Provides reliable cross-session comparisons regardless of conversation duration.",
    "lexical3": "Honor\u00e9's Statistic",
    "lexical3Desc": "Proportion of words used only once. Higher values indicate richer vocabulary; decline signals word-finding difficulties.",
    "lexical4": "Content Density",
    "lexical4Desc": "Ratio of content words to function words. AD patients shift toward semantically empty language as access to specific vocabulary degrades.",
    "lexical5": "Word Frequency Level",
    "lexical5Desc": "Distribution of common vs. rare words. Alzheimer's patients increasingly rely on high-frequency, generic terms.",
    "lexical6": "Pronoun-to-Noun Ratio",
    "lexical6Desc": "Referential specificity marker. Pronouns replace specific nouns ('it' instead of 'the kitchen') \u2014 effect size 0.9 for AD.",
    "lexical7": "Generic Substitution Rate",
    "lexical7Desc": "Frequency of generic terms like 'thing' and 'stuff' replacing specific nouns. Increases as semantic access degrades.",
    "lexical8": "Light Verb Ratio",
    "lexical8Desc": "Proportion of semantically light verbs (make, do, get). Helps distinguish AD from normal aging.",
    "domainSyntactic": "Syntactic Complexity (10% weight \u2014 8 indicators)",
    "syntactic1": "Mean Length of Utterance",
    "syntactic1Desc": "Average words per sentence. One of the two most crucial features for AD classification (Fronters 2024). Effect size 0.65.",
    "syntactic2": "Subordination Index",
    "syntactic2Desc": "Ratio of subordinate to total clauses. Grammar complexity drops as syntactic processing demands exceed capacity.",
    "syntactic3": "Sentence Completeness",
    "syntactic3Desc": "Rate of grammatically complete sentences. AD introduces more fragments and abandoned constructions.",
    "syntactic4": "Embedding Depth",
    "syntactic4Desc": "Maximum parse tree depth for clause nesting. Reduced depth reflects declining ability to maintain complex structures.",
    "syntactic5": "Passive Construction Ratio",
    "syntactic5Desc": "Grammar sophistication marker. Passive constructions require more complex syntactic processing.",
    "domainCoherence": "Semantic Coherence (20% weight \u2014 9 indicators)",
    "coherence1": "Idea Density",
    "coherence1Desc": "Propositions per utterance \u2014 the STRONGEST AD predictor. The Nun Study showed low idea density at age 22 predicted AD 60 years later with near-perfect accuracy. Effect size 1.25.",
    "coherence2": "Topic Maintenance",
    "coherence2Desc": "On-topic utterance ratio. Increasing topic drift signals executive function decline and semantic memory involvement.",
    "coherence3": "Referential Coherence",
    "coherence3Desc": "Pronoun-antecedent clarity \u2014 the BEST differentiator between AD and depression. AD degrades referential links; depression preserves them.",
    "coherence4": "Temporal Sequencing",
    "coherence4Desc": "Accuracy of event ordering in narratives. Temporal confusion is an early hippocampal dysfunction marker.",
    "coherence5": "Information Units",
    "coherence5Desc": "Content completeness vs expected units (Cookie Theft standard). Directly measures semantic memory access.",
    "coherence6": "Local Coherence",
    "coherence6Desc": "Adjacent sentence semantic similarity. Declining local coherence indicates difficulty maintaining thought flow.",
    "coherence7": "Topic Entropy",
    "coherence7Desc": "Topic spread measurement. AD shows chaotic high entropy; depression shows narrow low entropy (rumination).",
    "domainFluency": "Speech Fluency (12% weight \u2014 11 indicators)",
    "fluency1": "Long Pause Ratio",
    "fluency1Desc": "Extended pauses (>2s) per utterance \u2014 one of the two most crucial features (with MLU) for AD detection. Effect size 0.90.",
    "fluency2": "Within-Clause Pause Rate",
    "fluency2Desc": "Mid-sentence pauses, especially before nouns \u2014 indicates word-finding difficulty. AD-specific pattern (vs. boundary pauses in depression).",
    "fluency3": "Filled Pause Rate",
    "fluency3Desc": "Frequency of 'um', 'uh', 'like' per 100 words. Changes reflect real-time word retrieval effort.",
    "fluency4": "False Start Rate",
    "fluency4Desc": "Abandoned and restarted utterances. Increasing false starts indicate cognitive overload during speech production.",
    "fluency5": "Repetition Rate",
    "fluency5Desc": "Phrase repetition frequency. Working memory limitations cause unintentional repetition of content.",
    "fluency6": "Response Latency",
    "fluency6Desc": "Time to first word after prompt. Increased latency correlates with tau protein burden (Young et al. 2024).",
    "fluency7": "Speech Rate",
    "fluency7Desc": "Words per minute. Speaking slowly correlates with tau burden even in cognitively normal individuals.",
    "fluency8": "Session Variability",
    "fluency8Desc": "Cross-session consistency. AD shows monotonic decline; depression shows episodic fluctuation (high variability).",
    "domainMemory": "Memory & Recall (10% weight \u2014 6 indicators)",
    "memory1": "Free Recall Accuracy",
    "memory1Desc": "Unprompted memory retrieval. Both AD and depression show poor free recall, making this insufficient alone for differential.",
    "memory2": "Cued Recall Response",
    "memory2Desc": "THE definitive AD vs. depression differentiator. AD: poor cued recall (storage deficit). Depression: good cued recall (retrieval deficit). Effect size 1.0.",
    "memory3": "Recognition Accuracy",
    "memory3Desc": "Correct identification from options (FCSRT protocol). Builds on free/cued recall for graduated memory assessment.",
    "memory4": "Temporal Precision",
    "memory4Desc": "Accuracy of dates and timeframes in recall. Early marker of episodic memory degradation.",
    "memory5": "Intrusion Errors",
    "memory5Desc": "False memories during recall attempts. Early AD marker with effect size 0.7 \u2014 patients confabulate without awareness.",
    "memory6": "Semantic Fluency",
    "memory6Desc": "Category naming ability (e.g., 'name all animals in 60 seconds'). Screens for semantic knowledge network decline.",
    "domainDiscourse": "Discourse & Pragmatics (6% weight \u2014 5 indicators)",
    "discourse1": "Circumlocution Rate",
    "discourse1Desc": "Talking around words ('that thing you hold water with' instead of 'cup'). Active compensation for word-finding failure.",
    "discourse2": "Self-Correction Rate",
    "discourse2Desc": "Error detection and repair ability \u2014 a unique metacognitive marker. AD patients lose awareness of errors; all other conditions preserve self-monitoring.",
    "discourse3": "Metalinguistic Awareness",
    "discourse3Desc": "Explicit awareness of language difficulty ('what's the word?'). Follows an inverted-U pattern: increases in early AD, decreases as anosognosia develops.",
    "discourse4": "Topic Diversity",
    "discourse4Desc": "Range of conversational topics. AD narrows topics (executive control loss); depression narrows to negative themes.",
    "discourse5": "Perseveration Rate",
    "discourse5Desc": "Unaware repetition of content across turns. Distinct from conscious repetition \u2014 indicates frontal lobe involvement.",
    "domainAffective": "Affective & Mood (5% weight \u2014 6 indicators)",
    "affective1": "Self-Referential Pronouns",
    "affective1Desc": "I/me/my frequency \u2014 the strongest depression-specific linguistic marker (effect size 0.8). Elevated in depression due to self-focused rumination, NOT elevated in AD.",
    "affective2": "Negative Valence Words",
    "affective2Desc": "Negative emotion language frequency. Depression-specific: elevated hopelessness and negativity. AD shows neutral tone with content loss instead.",
    "affective3": "Absolutist Language",
    "affective3Desc": "Always/never/everything/nothing usage. Cognitive distortion pattern specific to depression ('I never do anything right').",
    "affective4": "Future Reference Ratio",
    "affective4Desc": "Forward-looking language proportion. Reduced future references indicate hopelessness \u2014 a hallmark of clinical depression.",
    "affective5": "Hedonic Language",
    "affective5Desc": "Pleasure and enjoyment word frequency. Reduced hedonic language signals anhedonia (loss of ability to feel pleasure).",
    "affective6": "Conversational Engagement",
    "affective6Desc": "Active participation level (topic initiation + elaboration). Reduced engagement indicates emotional withdrawal pattern.",
    "domainAcoustic": "Acoustic Features (12% weight \u2014 11 indicators)",
    "acoustic1": "F0 Statistics & Voice Quality",
    "acoustic1Desc": "Mean F0, F0 SD (most consistent prodromal PD marker, AUC 0.80), F0 range, jitter, shimmer, and HNR. The PD quartet (HNR+RPDE+DFA+PPE) achieves 91.4% accuracy.",
    "acoustic2": "Spectral & Cepstral Features",
    "acoustic2Desc": "MFCC-2 (highest SHAP feature for depression, 0.069), CPP, spectral harmonicity. Cross-cultural depression markers that reflect physiological psychomotor changes.",
    "acoustic3": "Energy & Formant Features",
    "acoustic3Desc": "Energy dynamic range (monoloudness in PD), F1/F2 ratio (vowel space compression). Extracted via parselmouth + librosa + nolds Python pipeline.",
    "domainPdMotor": "PD Motor Speech (10% weight \u2014 12 indicators)",
    "pdMotor1": "Nonlinear Dynamics (PD Quartet)",
    "pdMotor1Desc": "PPE (85.6% alone), RPDE, DFA, D2. The {HNR, RPDE, DFA, PPE} combination achieves 91.4% PD detection accuracy with kernel SVM (Little 2009).",
    "pdMotor2": "Articulatory Features",
    "pdMotor2Desc": "Vowel Space Area, VAI, DDK syllable rate (77.4% MSA accuracy), DDK regularity, Voice Onset Time, spirantization index. Covers all 5 PD speech subsystems.",
    "pdMotor3": "Motor Speech Dynamics",
    "pdMotor3Desc": "Oral festination (involuntary speeding), connected speech monopitch (AUC 0.80 PD, 0.65 prodromal RBD). Enables PD vs MSA vs PSP vs ET differential.",
    "claudeLabel": "Claude Integration",
    "claudeTitle": "Extended Thinking for",
    "claudeHighlight": "Clinical Analysis",
    "claudeDesc": "AlzheimerVoice leverages Claude Opus 4.6's extended thinking capability \u2014 allocating up to 16,000 tokens of internal reasoning before producing each analysis. This allows the model to consider the full complexity of linguistic patterns, personal history, and confounding factors before generating clinically relevant insights.",
    "claudeFeature1": "Multi-session trajectory analysis with trend detection",
    "claudeFeature2": "Confounder identification: illness, medication, mood, fatigue",
    "claudeFeature3": "Domain-specific pattern recognition across all 85 indicators",
    "claudeFeature4": "Confidence-weighted scoring with uncertainty quantification",
    "claudeFeature5": "Natural language clinical narratives for weekly reports",
    "validationLabel": "Clinical Validation",
    "validationTitle": "Research",
    "validationHighlight": "Foundation",
    "validationDesc": "The CVF Engine's approach is grounded in decades of peer-reviewed research in computational linguistics and neurodegenerative disease detection.",
    "validationStudies": "Key Studies",
    "study1": "Fraser et al. (2016) \u2014 81.92% accuracy detecting Alzheimer's from speech transcripts using 370 computational linguistic features.",
    "study2": "Snowdon et al. (1996) \u2014 The Nun Study: Low idea density at age 22 predicted Alzheimer's 60+ years later with near-perfect accuracy.",
    "study3": "Young et al. (2024) \u2014 Speaking slowly + frequent pauses correlated with tau protein burden in 238 cognitively normal adults. Speech preceded memory changes.",
    "study4": "Fronters (2024) \u2014 MLU + Long Pause Ratio identified as the two most crucial features, achieving ~88% accuracy across ML classifiers.",
    "study5": "Luz et al. (2020) \u2014 ADReSS Challenge: Established rigorous benchmarks for AD detection from speech across multiple research teams.",
    "study6": "Eyigoz et al. (2020) \u2014 Framingham Heart Study: 87 linguistic features outperformed APOE genotype and demographics for AD prediction.",
    "study7": "Amini et al. (2024) \u2014 78.5% accuracy, 81.1% sensitivity predicting MCI-to-AD progression over 6 years from speech analysis.",
    "backToHome": "Back to Home"
  },
  "familyPage": {
    "heroTitle": "Protecting the People",
    "heroHighlight": "You Love Most",
    "heroSubtitle": "AlzheimerVoice gives families something priceless: the ability to detect cognitive changes in loved ones years before traditional methods \u2014 through simple, natural conversations.",
    "storyLabel": "Why It Matters",
    "storyTitle": "Every Family Has",
    "storyHighlight": "a Story",
    "storyP1": "It often starts with something small. A repeated question. A forgotten name. A pause where there never used to be one. And by the time the family notices, the disease has often been progressing silently for years.",
    "storyP2": "Alzheimer's affects more than the person diagnosed \u2014 it reshapes entire families. The uncertainty, the delayed diagnosis, the feeling of lost time. AlzheimerVoice was built to give families back what matters most: <strong>time</strong>.",
    "storyP3": "With AlzheimerVoice, you don't have to wait for something to feel wrong. Continuous monitoring means cognitive changes are detected at their earliest, most subtle stages \u2014 when intervention can make the biggest difference.",
    "dignityLabel": "Dignity First",
    "dignityTitle": "Natural Monitoring That",
    "dignityHighlight": "Preserves Dignity",
    "dignityDesc": "Your loved one never feels tested, examined, or reduced to a patient. AlzheimerVoice works through warm, natural conversations about their own life \u2014 their memories, their stories, their experiences.",
    "dignity1Title": "No Clinical Setting Required",
    "dignity1Desc": "Monitoring happens through regular phone calls from the comfort of home. No appointments, no waiting rooms, no intimidating medical equipment.",
    "dignity2Title": "Conversations, Not Tests",
    "dignity2Desc": "AI-guided calls are designed to feel like catching up with an old friend. Topics are drawn from your loved one's own memories and life experiences.",
    "dignity3Title": "Complete Privacy",
    "dignity3Desc": "All conversations are processed with strict privacy protections. No data is sold, shared, or used for anything other than your loved one's cognitive monitoring.",
    "dignity4Title": "Family-Centered Reports",
    "dignity4Desc": "Weekly reports are written in clear, jargon-free language. You don't need a medical degree to understand your loved one's cognitive health.",
    "peaceMindLabel": "Peace of Mind",
    "peaceMindTitle": "From Worry to",
    "peaceMindHighlight": "Confidence",
    "peace1Title": "Know Early",
    "peace1Desc": "Detect subtle cognitive changes years before they become noticeable. Early awareness means more options and better outcomes.",
    "peace2Title": "Plan Ahead",
    "peace2Desc": "Early detection gives families critical time for care planning, financial preparation, legal arrangements, and treatment exploration.",
    "peace3Title": "Stay Connected",
    "peace3Desc": "Regular AI-guided conversations keep your loved one engaged and socially connected \u2014 proven to support cognitive health.",
    "peace4Title": "Act With Confidence",
    "peace4Desc": "Data-driven insights replace uncertainty. Know when it's time to talk to a doctor, backed by objective cognitive monitoring data.",
    "quoteText": "If we had known earlier, we would have had more time. More conversations. More moments where they were fully themselves. That's what early detection gives you \u2014 time.",
    "quoteAttribution": "The motivation behind AlzheimerVoice",
    "ctaTitle": "Give Your Family the Gift of",
    "ctaHighlight": "Early Awareness",
    "ctaDesc": "Explore the full open source Cognitive Voice Fingerprint engine on GitHub and build your own cognitive monitoring tools.",
    "ctaButton": "Open Source on GitHub",
    "backToHome": "Back to Home"
  },
  "opensource": {
    "heroTitle": "Open Source",
    "heroHighlight": "Cognitive Science",
    "heroSubtitle": "AlzheimerVoice's core CVF Engine is fully open source under the MIT license. We believe that technology for detecting cognitive decline should be accessible to everyone.",
    "repoLabel": "Repository",
    "repoTitle": "MIT Licensed &",
    "repoHighlight": "Community Driven",
    "repoDesc": "The complete source code is available on GitHub. Fork it, modify it, deploy it locally, or build your own cognitive analysis tools on top of it.",
    "repoUrl": "github.com/remifrancois/cognitivevoicefingerprint",
    "repoStars": "Get V5 Cognitive Voice Fingerprint (CVF)",
    "repoFork": "Fork Repository",
    "repoDocs": "Documentation",
    "coreLabel": "Core Engine",
    "coreTitle": "What's",
    "coreHighlight": "Included",
    "core1Title": "CVF Engine V5 Core",
    "core1Desc": "The complete 85-indicator two-stream pipeline across 9 domains. Analyze speech audio and transcripts to generate cognitive vectors using acoustic processing and any compatible LLM.",
    "core2Title": "Baseline System",
    "core2Desc": "Individual baseline computation (14-21 sessions) and z-score drift detection algorithms. Statistical comparison engine with configurable sensitivity thresholds.",
    "core3Title": "Differential Diagnosis",
    "core3Desc": "35-rule evidence-based system distinguishing 8 conditions: Alzheimer\u2019s, depression, Parkinson\u2019s, MSA, PSP, medication effects, grief, and normal aging.",
    "core4Title": "Report Generator",
    "core4Desc": "Weekly narrative report generation using AI. Produces both family-friendly summaries and detailed clinical reports with scoring breakdowns.",
    "customLabel": "Customization",
    "customTitle": "Build Your",
    "customHighlight": "Own Solution",
    "customDesc": "The open source engine is designed to be modular and extensible. Swap out components, add your own analysis dimensions, or integrate with your existing infrastructure.",
    "custom1Title": "Voice API Flexibility",
    "custom1Desc": "Switch between voice providers \u2014 Twilio, Vonage, or any SIP-compatible service. The engine is voice-API agnostic.",
    "custom2Title": "LLM Provider Switching",
    "custom2Desc": "While optimized for Claude, the engine supports any OpenAI-compatible API. Use GPT-4, Llama, Mistral, or your own fine-tuned models.",
    "custom3Title": "Local Deployment",
    "custom3Desc": "Run entirely on your own infrastructure. No external API calls required if you use a local LLM. Full data sovereignty guaranteed.",
    "custom4Title": "Custom Indicators",
    "custom4Desc": "Add or modify cognitive indicators beyond the default 85. Define custom scoring rubrics tailored to specific conditions or research needs.",
    "saasLabel": "SaaS Option",
    "saasTitle": "Prefer a Managed",
    "saasHighlight": "Solution?",
    "saasDesc": "Don't want to self-host? AlzheimerVoice also offers a fully managed SaaS platform with all the features of the open source engine, plus dedicated infrastructure, automatic updates, and clinical support.",
    "saasFeature1": "Managed infrastructure with 99.9% uptime SLA",
    "saasFeature2": "Automatic updates and security patches",
    "saasFeature3": "HIPAA-compliant hosting and data handling",
    "saasFeature4": "Dedicated onboarding and support team",
    "saasButton": "Family Access Demo",
    "backToHome": "Back to Home"
  },
  "demo": {
    "heroTitle": "See AlzheimerVoice",
    "heroHighlight": "In Action",
    "heroSubtitle": "This is a hackathon demo built at Cerebral Valley x Anthropic, February 2026. Request a walkthrough to see how the Cognitive Voice Fingerprint engine detects subtle linguistic patterns in real-time.",
    "formLabel": "Hackathon Demo",
    "formTitle": "Schedule Your",
    "formHighlight": "Demo Session",
    "formDesc": "Fill out the form below and our team will contact you to schedule a personalized demonstration of the CVF Engine.",
    "fieldName": "Full Name",
    "fieldNamePlaceholder": "Enter your full name",
    "fieldEmail": "Email Address",
    "fieldEmailPlaceholder": "you@organization.com",
    "fieldOrg": "Organization",
    "fieldOrgPlaceholder": "Hospital, research lab, or company name",
    "fieldRole": "Your Role",
    "fieldRolePlaceholder": "Select your role",
    "roleResearcher": "Researcher",
    "roleClinician": "Clinician",
    "roleCaregiver": "Family Caregiver",
    "roleDeveloper": "Developer",
    "roleOther": "Other",
    "fieldMessage": "What interests you most?",
    "fieldMessagePlaceholder": "Tell us about your use case...",
    "submitButton": "Request Hackathon Demo",
    "submitNote": "We'll respond within 24 hours. No spam, ever.",
    "expectLabel": "What to Expect",
    "expectTitle": "Your Demo",
    "expectHighlight": "Experience",
    "expect1Title": "Live Analysis Demo",
    "expect1Desc": "Watch the CVF Engine V5 process a real conversation transcript in real-time, extracting all 85 cognitive indicators and generating a differential diagnosis.",
    "expect2Title": "Dashboard Walkthrough",
    "expect2Desc": "Explore the monitoring dashboard \u2014 see how baseline comparisons work, how drift is detected, and how the 4-stage cascade model identifies progression.",
    "expect3Title": "Report Examples",
    "expect3Desc": "Review sample weekly narrative reports showing how cognitive trends are communicated to families and clinicians in clear, actionable language.",
    "expect4Title": "Q&A Session",
    "expect4Desc": "Ask our team anything about the science, the technology, deployment options, or how AlzheimerVoice can fit your specific needs.",
    "previewLabel": "Preview",
    "previewTitle": "Platform",
    "previewHighlight": "Highlights",
    "preview1": "Real-time 85-indicator cognitive analysis across 9 domains (text + audio)",
    "preview2": "Individual baseline tracking with personalized z-score drift detection",
    "preview3": "Differential diagnosis across 8 conditions (AD, depression, PD, MSA, PSP, medication, grief, aging)",
    "preview4": "AI-generated weekly family and medical narrative reports",
    "preview5": "Multi-language conversation support (9 languages)",
    "preview6": "HIPAA-compliant data handling with zero conversation storage",
    "backToHome": "Back to Home"
  },
  "privacy": {
    "heroTitle": "Your Privacy Is",
    "heroHighlight": "Non-Negotiable",
    "heroSubtitle": "AlzheimerVoice is built with privacy as a core architectural principle. We collect zero personal data. Your cognitive health monitoring should never come at the cost of your privacy.",
    "policyLabel": "Zero Collection",
    "policyTitle": "No Data",
    "policyHighlight": "Collection Policy",
    "policyDesc": "AlzheimerVoice does not collect, store, or sell personal data. All cognitive analysis happens in real-time, and no conversation recordings or transcripts are retained beyond the immediate processing window.",
    "policy1Title": "No Conversation Storage",
    "policy1Desc": "Audio recordings and transcripts are processed in real-time and immediately discarded. Only computed cognitive feature vectors are retained for baseline comparison.",
    "policy2Title": "No Third-Party Sharing",
    "policy2Desc": "Your data is never shared with, sold to, or accessed by third parties. Period. No advertising, no data brokers, no exceptions.",
    "policy3Title": "No Behavioral Tracking",
    "policy3Desc": "We don't track user behavior, browsing patterns, or usage analytics beyond what's strictly necessary for the service to function.",
    "policy4Title": "User-Controlled Data",
    "policy4Desc": "All stored cognitive vectors can be exported or permanently deleted at any time by the account holder. Full GDPR data portability guaranteed.",
    "hipaaLabel": "HIPAA",
    "hipaaTitle": "HIPAA Safety",
    "hipaaHighlight": "Measures",
    "hipaaDesc": "AlzheimerVoice is designed to meet HIPAA (Health Insurance Portability and Accountability Act) requirements for protected health information.",
    "hipaa1Title": "End-to-End Encryption",
    "hipaa1Desc": "All data in transit is protected with TLS 1.3 encryption. Stored cognitive vectors are encrypted at rest using AES-256.",
    "hipaa2Title": "Access Controls",
    "hipaa2Desc": "Role-based access control ensures only authorized users can view cognitive data. All access is logged and auditable.",
    "hipaa3Title": "Audit Logging",
    "hipaa3Desc": "Complete audit trail of all data access, modifications, and deletions. Logs are tamper-proof and retained per HIPAA requirements.",
    "hipaa4Title": "Business Associate Agreements",
    "hipaa4Desc": "BAAs are available for all healthcare partners. Cloud infrastructure providers are HIPAA-certified and covered under their own BAAs.",
    "encryptionLabel": "Encryption",
    "encryptionTitle": "Data",
    "encryptionHighlight": "Protection",
    "encryptionDesc": "Multiple layers of encryption protect data at every stage of processing.",
    "encrypt1": "TLS 1.3 for all data in transit",
    "encrypt2": "AES-256 encryption for data at rest",
    "encrypt3": "Encrypted database connections",
    "encrypt4": "Key rotation every 90 days",
    "encrypt5": "Hardware security modules (HSM) for key storage",
    "backToHome": "Back to Home"
  },
  "legal": {
    "heroTitle": "Legal &",
    "heroHighlight": "Licensing",
    "heroSubtitle": "AlzheimerVoice is committed to transparency in how we build, license, and envision the future of accessible cognitive health technology.",
    "mitLabel": "License",
    "mitTitle": "MIT Open Source",
    "mitHighlight": "License",
    "mitDesc": "The AlzheimerVoice CVF Engine is released under the MIT License \u2014 one of the most permissive open source licenses available. You are free to use, modify, distribute, and build upon this software for any purpose.",
    "mitPermit1": "Commercial use",
    "mitPermit2": "Modification",
    "mitPermit3": "Distribution",
    "mitPermit4": "Private use",
    "mitCondition": "The only condition is that the original MIT license and copyright notice must be included in any copy or substantial portion of the software.",
    "hackathonLabel": "Origin",
    "hackathonTitle": "Cerebral Valley x",
    "hackathonHighlight": "Anthropic Hackathon",
    "hackathonDesc": "AlzheimerVoice was created at the Cerebral Valley x Anthropic Hackathon in February 2026. This event brought together developers, researchers, and AI enthusiasts to build meaningful applications using Anthropic's Claude AI.",
    "hackathonCredit1": "Built using Claude Opus 4.6 by Anthropic",
    "hackathonCredit2": "Developed during the February 2026 hackathon event",
    "hackathonCredit3": "Cerebral Valley community for the platform and inspiration",
    "hackathonCredit4": "All open source contributors and research community",
    "ngoLabel": "Future Vision",
    "ngoTitle": "Potential",
    "ngoHighlight": "NGO Future",
    "ngoDesc": "We envision AlzheimerVoice evolving beyond a hackathon project into a nonprofit organization dedicated to making cognitive health monitoring accessible worldwide.",
    "ngo1Title": "Global Accessibility",
    "ngo1Desc": "Cognitive decline affects families everywhere. As an NGO, AlzheimerVoice could provide free or subsidized monitoring to underserved communities worldwide.",
    "ngo2Title": "Research Partnerships",
    "ngo2Desc": "Nonprofit status enables deeper collaboration with academic institutions, hospitals, and research organizations without commercial conflicts of interest.",
    "ngo3Title": "Ethical AI Governance",
    "ngo3Desc": "An NGO structure ensures that decisions about cognitive health AI are guided by ethics and patient welfare \u2014 not shareholder returns.",
    "ngo4Title": "Community Ownership",
    "ngo4Desc": "The open source foundation means the technology belongs to everyone. An NGO would formalize this commitment to community ownership and transparent governance.",
    "disclaimerLabel": "Disclaimer",
    "disclaimerTitle": "Important",
    "disclaimerHighlight": "Notice",
    "disclaimerText": "AlzheimerVoice is currently a research and demonstration project. It is not a medical device and is not intended to diagnose, treat, cure, or prevent any disease. The Cognitive Voice Fingerprint analysis is for research and informational purposes only. Always consult qualified healthcare professionals for medical advice and diagnosis.",
    "backToHome": "Back to Home"
  },
  "compliance": {
    "heroTitle": "Compliance &",
    "heroHighlight": "Security",
    "heroSubtitle": "AlzheimerVoice implements comprehensive security and compliance measures throughout its architecture. Every layer of the system is designed with healthcare-grade protection.",
    "hipaaLabel": "HIPAA Standards",
    "hipaaTitle": "HIPAA",
    "hipaaHighlight": "Compliance Framework",
    "hipaaDesc": "Our architecture implements the HIPAA Security Rule's administrative, physical, and technical safeguards for electronic protected health information (ePHI).",
    "hipaa1Title": "Administrative Safeguards",
    "hipaa1Desc": "Security management processes, assigned security responsibility, workforce security training, and information access management policies are documented and enforced.",
    "hipaa2Title": "Technical Safeguards",
    "hipaa2Desc": "Access controls with unique user identification, emergency access procedures, automatic logoff, and encryption/decryption of all ePHI in transit and at rest.",
    "hipaa3Title": "Physical Safeguards",
    "hipaa3Desc": "Facility access controls, workstation security policies, device and media controls for all systems that process, store, or transmit ePHI.",
    "hipaa4Title": "Breach Notification",
    "hipaa4Desc": "Incident response plan with documented notification procedures. Any breach affecting 500+ individuals is reported within 60 days per HIPAA requirements.",
    "hipaa5Title": "Business Associate Agreements",
    "hipaa5Desc": "All third-party service providers handling ePHI execute BAAs. Cloud infrastructure (AWS) and AI providers are covered under their own HIPAA certifications.",
    "hipaa6Title": "Minimum Necessary Standard",
    "hipaa6Desc": "Access to patient data follows the minimum necessary principle. Users only see data required for their specific role \u2014 enforced at the API level with RBAC.",
    "gdprLabel": "GDPR",
    "gdprTitle": "GDPR",
    "gdprHighlight": "Data Protection",
    "gdprDesc": "For users in the European Economic Area, AlzheimerVoice complies with the General Data Protection Regulation.",
    "gdpr1Title": "Right to Access",
    "gdpr1Desc": "Users can request a complete export of all personal data held by AlzheimerVoice at any time, delivered in a machine-readable format within 30 days.",
    "gdpr2Title": "Right to Erasure",
    "gdpr2Desc": "Users can request permanent deletion of all personal data. Upon request, all cognitive vectors, baselines, and account data are irreversibly purged.",
    "gdpr3Title": "Data Minimization",
    "gdpr3Desc": "We only process data strictly necessary for cognitive monitoring. Conversation audio is discarded after real-time extraction \u2014 only feature vectors are retained.",
    "gdpr4Title": "Lawful Basis",
    "gdpr4Desc": "Processing is based on explicit user consent. Consent can be withdrawn at any time, triggering automatic data deletion per Article 7 of the GDPR.",
    "securityLabel": "Security Architecture",
    "securityTitle": "Defense in",
    "securityHighlight": "Depth",
    "securityDesc": "Multiple layers of security protect data at every stage of the processing pipeline.",
    "security1Title": "AES-256 Encryption at Rest",
    "security1Desc": "All stored data \u2014 cognitive vectors, baselines, user accounts \u2014 is encrypted using AES-256-GCM with per-record initialization vectors. Encryption keys are managed separately from data.",
    "security2Title": "TLS 1.3 in Transit",
    "security2Desc": "All API communication uses TLS 1.3 with forward secrecy. Certificate pinning prevents man-in-the-middle attacks. HSTS headers enforce HTTPS-only access.",
    "security3Title": "Role-Based Access Control",
    "security3Desc": "Five-tier RBAC system: Family, Clinician, Admin, Superadmin, and System. Each role has precisely scoped permissions enforced at the API gateway level.",
    "security4Title": "Service-to-Service Authentication",
    "security4Desc": "Internal services communicate using cryptographic service keys. The CVF Engine only accepts requests from the authenticated API gateway \u2014 never from clients directly.",
    "security5Title": "Rate Limiting & DDoS Protection",
    "security5Desc": "API rate limiting (100 requests/minute per user), request size limits, and CloudFront-level DDoS mitigation protect against abuse and denial-of-service attacks.",
    "security6Title": "Input Sanitization",
    "security6Desc": "All user inputs are validated and sanitized at the API boundary. SQL injection, XSS, and command injection attacks are prevented through parameterized queries and strict Content Security Policy.",
    "auditLabel": "Audit & Monitoring",
    "auditTitle": "Complete",
    "auditHighlight": "Audit Trail",
    "auditDesc": "Every action in the system is logged, monitored, and available for compliance review.",
    "audit1Title": "Immutable Audit Logs",
    "audit1Desc": "Every data access, modification, and deletion is recorded in tamper-proof audit logs with timestamps, user identity, IP address, and action details.",
    "audit2Title": "Real-Time Monitoring",
    "audit2Desc": "System health, error rates, and security events are monitored in real-time. Anomaly detection alerts the security team to unusual access patterns.",
    "audit3Title": "Access Review",
    "audit3Desc": "Quarterly access reviews ensure user permissions remain appropriate. Unused accounts are automatically deactivated after 90 days of inactivity.",
    "audit4Title": "Incident Response",
    "audit4Desc": "Documented incident response plan with defined severity levels, escalation procedures, and post-incident review process. Team is trained on response protocols.",
    "backToHome": "Back to Home"
  },
  "creators": {
    "heroTitle": "Meet the",
    "heroHighlight": "Creators",
    "heroSubtitle": "AlzheimerVoice was born from a shared conviction: that AI should serve the most vulnerable among us. Built at the Cerebral Valley x Anthropic Hackathon, February 2026.",
    "teamLabel": "The Team",
    "teamTitle": "Built With",
    "teamHighlight": "Purpose",
    "creator1Name": "Rmi F.",
    "creator1Role": "Lead Engineer & Architect",
    "creator1Bio": "Full-stack engineer with a passion for healthcare AI. Designed the CVF Engine architecture, the evidence-compiled scoring system, and the two-tier analysis pipeline. Believes technology should make healthcare more accessible, not more complex.",
    "creator1Quote": "Every family deserves access to early detection. The science exists \u2014 we just needed to make it accessible through a phone call.",
    "creator2Name": "Co-Creator  to be announced soon",
    "creator2Role": "Research & Clinical Design",
    "creator2Bio": "Researcher focused on computational linguistics and neurodegenerative disease markers. Curated the 60+ study evidence base, designed the differential diagnosis rules, and ensured every indicator is grounded in peer-reviewed science.",
    "creator2Quote": "The indicators don't lie. When you compile decades of research into a single engine, the patterns become unmistakable.",
    "visionLabel": "Our Vision",
    "visionTitle": "Why We",
    "visionHighlight": "Built This",
    "visionDesc": "Alzheimer's affects 55 million people worldwide and their families. Current diagnosis comes too late. We built AlzheimerVoice because we believe early detection should be as simple as a phone call.",
    "vision1Title": "Accessible to Everyone",
    "vision1Desc": "Open source, multi-language, deployable anywhere. No expensive medical equipment, no clinical visits required. Just a phone and a conversation.",
    "vision2Title": "Grounded in Science",
    "vision2Desc": "Every indicator, every weight, every threshold is traced to published research. No black-box AI \u2014 transparent, evidence-compiled reasoning.",
    "vision3Title": "Privacy by Design",
    "vision3Desc": "Zero data collection. Conversations are processed and discarded. Only cognitive vectors remain. Your loved one's privacy is non-negotiable.",
    "vision4Title": "Built for Families",
    "vision4Desc": "Not for investors, not for shareholders. For the daughter who calls her mother every day. For the son who wants to know if something is changing.",
    "hackathonLabel": "The Hackathon",
    "hackathonTitle": "Cerebral Valley x",
    "hackathonHighlight": "Anthropic",
    "hackathonDesc": "AlzheimerVoice was created during a 6-day sprint at the Cerebral Valley x Anthropic Hackathon in San Francisco, February 2026, with $500 in Claude Opus 4.6 API tokens to develop. What started as a hackathon project grew into a comprehensive cognitive monitoring platform.",
    "hackathon1": "6-day build sprint at Cerebral Valley, San Francisco",
    "hackathon2": "$500 in Claude Opus 4.6 API tokens by Anthropic",
    "hackathon3": "80 research papers compiled into the CVF V5 engine",
    "hackathon4": "Open sourced under MIT license from day one",
    "backToHome": "Back to Home"
  },
  "cvf": {
    "heroTitle": "Core Voice Framework",
    "heroHighlight": "V5 Engine",
    "heroSubtitle": "The first voice-based cognitive fingerprinting system to combine acoustic signal processing with LLM-powered linguistic analysis. 85 indicators, 9 domains, 80 research papers, 35 differential rules, 3 cascade types \u2014 fully open source.",
    "archLabel": "Architecture",
    "archTitle": "Two-Stream Evidence-Compiled",
    "archHighlight": "Architecture",
    "archDesc": "CVF V5 is the paradigm shift from text-only to multimodal with dual-pass analysis. Two parallel streams \u2014 acoustic signal processing and LLM linguistic analysis \u2014 merge into an 85-indicator vector processed by a deterministic scoring engine. Built from systematic analysis of 80 research papers across Alzheimer\u2019s, Depression, and Parkinson\u2019s disease. V5 captures ~75% of the known voice biomarker signal \u2014 up from V4\u2019s ~25%.",
    "tier1Title": "Stream 1: Acoustic Pipeline",
    "tier1Desc": "Audio is converted to 16kHz WAV via ffmpeg, then processed by a Python pipeline using parselmouth (Praat), librosa, and nolds. Extracts 21 acoustic indicators including jitter, shimmer, HNR, MFCCs, F0 statistics, and nonlinear dynamics (RPDE, DFA, PPE). Cost: $0.00 \u2014 runs locally.",
    "tier2Title": "Stream 2: Text Pipeline",
    "tier2Desc": "Claude Sonnet 4.5 analyzes the transcript, extracting 64 linguistic indicators across 7 text domains. Includes 17 V5 indicators: MATTR, Imageability, Age of Acquisition, Yngve depth, death-words, ruminative language, embedding coherence, and more. Cost: ~$0.07 per session.",
    "tier3Title": "Vector Merge + Scoring Engine",
    "tier3Desc": "Both streams merge into a single 85-indicator vector (nulls for missing audio). The deterministic V5 scoring engine computes z-scores, 9 domain scores, composite score, 3 cascade detectors, and 35-rule differential across 8 conditions. No trained ML model \u2014 every rule is traceable to published research.",
    "tier4Title": "Graceful Degradation",
    "tier4Desc": "When audio is unavailable, acoustic (12%) and PD motor (10%) domain weights are redistributed proportionally across text domains. V5 text-only is always \u2265 V4 performance. No session is ever worse than V4 just because audio failed.",
    "tier5Title": "Weekly Deep Analysis",
    "tier5Desc": "Claude Opus 4.6 with extended thinking (20K token budget) cross-validates the differential, discovers micro-patterns, generates family and medical reports, and designs next week\u2019s probes. Cost: $0.30\u2013$0.50/week. Total: $0.80\u2013$1.00/week per patient.",
    "domainsLabel": "9 Domains",
    "domainsTitle": "85 Indicators Across",
    "domainsHighlight": "9 Cognitive Domains",
    "domainsDesc": "Seven linguistic domains from text analysis plus two acoustic domains from audio processing. Every indicator has an evidence strength rating (1\u20135), a base weight, and condition-specific direction vectors.",
    "lexicalName": "Lexical Richness",
    "lexicalWeight": "15% weight",
    "lexicalCount": "17 indicators",
    "lexicalDesc": "Vocabulary diversity, word selection, and psycholinguistic properties. Expanded with MATTR, imageability, age of acquisition, death-words, ruminative language, and more. Lexical decline is one of the earliest AD signals.",
    "lex1": "Type-Token Ratio (TTR)",
    "lex1D": "Unique words / total words. Evidence: 5/5. Effect size: 1.0 for AD. Among the earliest detectable markers.",
    "lex2": "Brunet's Index",
    "lex2D": "N^(V^(-0.172)). Evidence: 4/5. Length-independent lexical richness for reliable cross-session comparison.",
    "lex3": "Honor\u00e9's Statistic",
    "lex3D": "100\u00d7log(N)/(1-V1/V). Evidence: 4/5. Proportion of hapax legomena (words used once). Decline = word-finding difficulty.",
    "lex4": "Content Density",
    "lex4D": "Content words / total words. Evidence: 5/5. Effect size: 0.8. AD patients shift toward semantically empty language.",
    "lex5": "Word Frequency Level",
    "lex5D": "Mean frequency rank of words used. Evidence: 4/5. Effect size: 0.7. AD patients rely on high-frequency generic terms.",
    "lex6": "Pronoun-to-Noun Ratio",
    "lex6D": "Pronouns / nouns. Evidence: 5/5. Effect size: 0.9. 'It' replaces 'the kitchen' as semantic access degrades.",
    "lex7": "Generic Substitution Rate",
    "lex7D": "Generic words / content words. Evidence: 4/5. 'Thing' and 'stuff' replace specific nouns.",
    "lex8": "Light Verb Ratio",
    "lex8D": "Light verbs (make, do, get) / total verbs. Evidence: 3/5. Distinguishes AD from normal aging.",
    "lex9": "Moving-Average TTR (MATTR)",
    "lex9D": "Length-independent TTR using moving window. Evidence: 4/5. Superior to standard TTR for short speech samples (Fraser 2015).",
    "lex10": "Word Imageability",
    "lex10D": "Mean imageability rating of words used. Evidence: 4/5. AD patients shift to concrete, imageable words as abstract vocabulary is lost.",
    "lex11": "Age of Acquisition (AoA)",
    "lex11D": "Mean age-of-acquisition of vocabulary. Evidence: 4/5. AD patients regress to earlier-acquired words.",
    "lex12": "Noun:Verb Ratio",
    "lex12D": "Nouns / verbs. Evidence: 4/5. AD decreases nouns faster than verbs \u2014 distinct from Pronoun:Noun ratio.",
    "lex13": "Closed:Open Class Ratio",
    "lex13D": "Function words / content words. Evidence: 3/5. More closed-class words in AD speech (Orimaye 2017).",
    "lex14": "Death-Related Words",
    "lex14D": "Death/dying/funeral word frequency. Evidence: 4/5. Depression-specific marker \u2014 consistent across reviews.",
    "lex15": "Ruminative Language",
    "lex15D": "Repetitive negative self-focus patterns. Evidence: 4/5. Strong depression marker \u2014 repeated finding.",
    "lex16": "Total Verbal Output",
    "lex16D": "Total word count per session. Evidence: 4/5. Simplest psychomotor marker across all conditions.",
    "lex17": "Not-in-Dictionary Rate",
    "lex17D": "Proportion of words absent from standard dictionary. Evidence: 3/5. Captures paraphasias and neologisms.",
    "syntacticName": "Syntactic Complexity",
    "syntacticWeight": "10% weight",
    "syntacticCount": "8 indicators",
    "syntacticDesc": "Sentence structure and grammatical sophistication. Syntactic decline follows semantic decline in the AD cascade (Stage 2).",
    "syn1": "Mean Length of Utterance (MLU)",
    "syn1D": "Words per utterance. Evidence: 5/5. Effect size: 0.65. One of the two most crucial features across all ML classifiers (Fronters 2024).",
    "syn2": "Subordination Index",
    "syn2D": "Subordinate clauses / total clauses. Evidence: 4/5. Grammar complexity drops as processing demands exceed capacity.",
    "syn3": "Sentence Completeness",
    "syn3D": "Complete / total sentences. Evidence: 3/5. AD introduces fragments and abandoned constructions.",
    "syn4": "Embedding Depth",
    "syn4D": "Mean max clause depth. Evidence: 3/5. Reduced depth reflects declining ability to maintain nested structures.",
    "syn5": "Passive Construction Ratio",
    "syn5D": "Passive / total sentences. Evidence: 2/5. Requires more complex syntactic processing.",
    "syn6": "Yngve Depth",
    "syn6D": "Mean Yngve parse-tree embeddedness score. Evidence: 4/5. More sensitive than MLU for AD detection (Fraser 2015).",
    "syn7": "CFG Rule Diversity",
    "syn7D": "Number of unique context-free grammar production rules. Evidence: 3/5. Grammatical construction variety measure.",
    "syn8": "Sentence Fragment Rate",
    "syn8D": "Fragments / total utterances. Evidence: 3/5. Direct incomplete utterance measure \u2014 increases in AD.",
    "semanticName": "Semantic Coherence",
    "semanticWeight": "20% weight",
    "semanticCount": "9 indicators",
    "semanticDesc": "The STRONGEST predictor domain. Idea density alone can predict AD 60+ years in advance (Nun Study). Referential coherence is THE best differentiator between AD and depression.",
    "sem1": "Idea Density",
    "sem1D": "Propositions / words. Evidence: 5/5. Effect size: 1.25. Nun Study: low density at age 22 \u2192 AD at age 78 with near-perfect accuracy.",
    "sem2": "Topic Maintenance",
    "sem2D": "On-topic / total utterances. Evidence: 5/5. Topic drift signals executive function decline.",
    "sem3": "Referential Coherence",
    "sem3D": "Pronouns with clear antecedent / total pronouns. Evidence: 5/5. THE differentiator: AD degrades, depression preserves.",
    "sem4": "Temporal Sequencing",
    "sem4D": "Correct event order / total events. Evidence: 4/5. Temporal confusion = early hippocampal marker.",
    "sem5": "Information Units",
    "sem5D": "Correct units / expected (Cookie Theft). Evidence: 5/5. Gold standard semantic memory assessment.",
    "sem6": "Local Coherence",
    "sem6D": "Adjacent sentence similarity. Evidence: 4/5. Thought flow maintenance measurement.",
    "sem7": "Topic Entropy",
    "sem7D": "-\u03a3 p(topic)\u00d7log(p(topic)). Evidence: 3/5. AD: chaotic high entropy. Depression: narrow low entropy.",
    "sem8": "Utterance Cosine Similarity",
    "sem8D": "Mean cosine similarity between consecutive utterances. Evidence: 4/5. Repetitiveness measure (Fraser 2015).",
    "sem9": "Embedding-Based Coherence",
    "sem9D": "Semantic coherence from sentence embeddings. Evidence: 5/5. Predicts AD 7.6 years pre-diagnosis with AUC 0.74 (Eyigoz 2020).",
    "temporalName": "Speech Fluency / Temporal",
    "temporalWeight": "12% weight",
    "temporalCount": "11 indicators",
    "temporalDesc": "The EARLIEST pre-symptomatic signal. Young et al. 2024 showed speaking slowly + frequent pauses correlate with tau protein burden in cognitively normal adults.",
    "tmp1": "Long Pause Ratio (LPR)",
    "tmp1D": "Pauses >2s / utterances. Evidence: 5/5. Effect size: 0.90. With MLU, one of the two most crucial features (~88% accuracy).",
    "tmp2": "Within-Clause Pause Rate",
    "tmp2D": "Within-clause / total pauses. Evidence: 4/5. AD: pauses WITHIN clauses (word-finding). Depression: pauses at BOUNDARIES (emotional regulation).",
    "tmp3": "Filled Pause Rate",
    "tmp3D": "Fillers / 100 words. Evidence: 3/5. 'Um', 'uh' frequency reflects real-time retrieval effort.",
    "tmp4": "False Start Rate",
    "tmp4D": "Abandoned / total utterances. Evidence: 3/5. Cognitive overload during speech production.",
    "tmp5": "Repetition Rate",
    "tmp5D": "Repeated phrases / total. Evidence: 4/5. Working memory limitations cause unintentional repetition.",
    "tmp6": "Response Latency",
    "tmp6D": "Mean time to first word. Evidence: 5/5. Increased latency correlates with tau burden (Young 2024).",
    "tmp7": "Speech Rate",
    "tmp7D": "Words per minute. Evidence: 5/5. Slow speech correlates with tau even in cognitively normal individuals.",
    "tmp8": "Session Variability",
    "tmp8D": "CV(composite over 7 days). Evidence: 3/5. AD: monotonic decline. Depression: episodic fluctuation.",
    "tmp9": "Articulation Rate",
    "tmp9D": "Syllables per second excluding pauses. Evidence: 4/5. Combines audio and text data. PD and AD both show reduction.",
    "tmp10": "Pause Duration Variability",
    "tmp10D": "Standard deviation of pause durations. Evidence: 3/5. Audio-derived. Irregular pauses indicate motor planning difficulty (PD).",
    "tmp11": "Speech-to-Silence Ratio",
    "tmp11D": "Speaking time / total time. Evidence: 4/5. Audio-derived. Reduced ratio in PD (bradykinesia) and depression (psychomotor retardation).",
    "memoryName": "Memory & Recall",
    "memoryWeight": "10% weight",
    "memoryCount": "6 indicators",
    "memoryDesc": "Implements the FCSRT protocol (Grober & Buschke) invisibly within conversation. The free vs. cued recall dissociation is THE memory-based AD vs. depression differentiator.",
    "mem1": "Free Recall Accuracy",
    "mem1D": "Correct unprompted recalls / prompts. Evidence: 5/5. Both AD and depression show poor free recall \u2014 insufficient alone.",
    "mem2": "Cued Recall Response",
    "mem2D": "Correct cued recalls / prompts. Evidence: 5/5. THE definitive test: AD = poor (storage deficit). Depression = good (retrieval deficit). Effect size: 1.0.",
    "mem3": "Recognition Accuracy",
    "mem3D": "Correct from options / total. Evidence: 4/5. Graduated assessment: if cued fails, try recognition.",
    "mem4": "Temporal Precision",
    "mem4D": "Correct dates / total temporal references. Evidence: 3/5. Early episodic memory marker.",
    "mem5": "Intrusion Errors",
    "mem5D": "False memories / recall attempts. Evidence: 4/5. Effect size: 0.7. AD patients confabulate without awareness.",
    "mem6": "Semantic Fluency",
    "mem6D": "Category items in 60s. Evidence: 5/5. Screens semantic knowledge network integrity.",
    "discourseName": "Discourse & Pragmatics",
    "discourseWeight": "6% weight",
    "discourseCount": "5 indicators",
    "discourseDesc": "Narrative structure and metacognitive awareness. Self-correction loss is a unique AD marker \u2014 patients lose the ability to detect their own errors.",
    "dis1": "Circumlocution Rate",
    "dis1D": "Circumlocutions / content words. Evidence: 4/5. 'That thing you hold water with' instead of 'cup'.",
    "dis2": "Self-Correction Rate",
    "dis2D": "Corrections / errors. Evidence: 3/5. THE metacognitive marker: AD loses self-monitoring, all other conditions preserve it.",
    "dis3": "Metalinguistic Awareness",
    "dis3D": "'What's the word?' count. Evidence: 3/5. Inverted-U: increases early AD (awareness of deficit), decreases late AD (anosognosia).",
    "dis4": "Topic Diversity",
    "dis4D": "Unique topics / duration. Evidence: 3/5. AD: narrows (executive loss). Depression: narrows to negative themes.",
    "dis5": "Perseveration Rate",
    "dis5D": "Repeated content / total. Evidence: 3/5. Unaware repetition indicates frontal lobe involvement.",
    "affectiveName": "Affective & Mood",
    "affectiveWeight": "5% weight",
    "affectiveCount": "6 indicators",
    "affectiveDesc": "Nearly orthogonal to AD \u2014 these 6 indicators specifically detect depression and emotional distress, enabling accurate differential diagnosis.",
    "aff1": "Self-Referential Pronouns",
    "aff1D": "(I+me+my) / total \u00d7 100. Evidence: 5/5. Effect size: 0.8. STRONGEST depression marker. Self-focused rumination, NOT elevated in AD.",
    "aff2": "Negative Valence Words",
    "aff2D": "Negative emotion / total words. Evidence: 5/5. Effect size: 0.8. Depression-specific: elevated negativity. AD: neutral tone.",
    "aff3": "Absolutist Language",
    "aff3D": "(always+never+everything+nothing) / total. Evidence: 4/5. Cognitive distortion pattern specific to depression.",
    "aff4": "Future Reference Ratio",
    "aff4D": "Future / total temporal refs. Evidence: 4/5. Reduced future references = hopelessness (depression hallmark).",
    "aff5": "Hedonic Language",
    "aff5D": "Pleasure words / total. Evidence: 4/5. Reduced = anhedonia (loss of ability to feel pleasure).",
    "aff6": "Conversational Engagement",
    "aff6D": "Topic initiations + elaborations / turns. Evidence: 3/5. Withdrawal pattern in depression.",
    "acousticName": "Acoustic Features",
    "acousticWeight": "12% weight",
    "acousticCount": "11 indicators",
    "acousticDesc": "Voice signal characteristics extracted via Python acoustic pipeline (parselmouth + librosa). The strongest cross-cultural depression markers and key indicators for all three conditions. Stream: Audio only.",
    "acu1": "Mean F0",
    "acu1D": "Average fundamental frequency (Hz). Evidence: 4/5. Gender-dependent (M~120Hz, F~220Hz). Depression lowers F0.",
    "acu2": "F0 Standard Deviation",
    "acu2D": "Pitch variability. Evidence: 5/5. MOST CONSISTENT prodromal PD marker (AUC 0.80). Monopitch signature.",
    "acu3": "F0 Range",
    "acu3D": "Max F0 - min F0. Evidence: 4/5. Reduced in PD (monopitch) and depression (flat affect).",
    "acu4": "Jitter (local)",
    "acu4D": "Cycle-to-cycle frequency perturbation. Evidence: 4/5. Vocal fold instability. Healthy <1.04%, PD often >1.5%.",
    "acu5": "Shimmer (local)",
    "acu5D": "Cycle-to-cycle amplitude perturbation. Evidence: 4/5. Healthy <3.81%, PD often >5%.",
    "acu6": "Harmonics-to-Noise Ratio (HNR)",
    "acu6D": "Voice clarity vs. noise. Evidence: 5/5. Part of PD quartet (91.4% accuracy). Healthy >20dB, PD <15dB.",
    "acu7": "MFCC Coefficient 2",
    "acu7D": "2nd Mel-frequency cepstral coefficient. Evidence: 5/5. HIGHEST SHAP feature for depression (0.069). Cross-cultural.",
    "acu8": "Cepstral Peak Prominence (CPP)",
    "acu8D": "Voice clarity measure. Evidence: 4/5. More robust than perturbation measures for all conditions.",
    "acu9": "Spectral Harmonicity",
    "acu9D": "Harmonic structure of voice spectrum. Evidence: 4/5. Depression cross-cultural marker (SHAP=0.036).",
    "acu10": "Energy Dynamic Range",
    "acu10D": "Volume variation range. Evidence: 3/5. Monoloudness (PD) or flat affect (depression).",
    "acu11": "Formant F1/F2 Ratio",
    "acu11D": "Vowel space indicator. Evidence: 3/5. PD vowel space compression marker.",
    "pdMotorName": "PD Motor Speech",
    "pdMotorWeight": "10% weight",
    "pdMotorCount": "12 indicators",
    "pdMotorDesc": "Dedicated Parkinson\u2019s engine covering all 5 speech subsystems. Nonlinear dynamics (the PD quartet: PPE+RPDE+DFA+HNR = 91.4% accuracy) plus articulatory features. Stream: Audio + Micro-task.",
    "pdm1": "Pitch Period Entropy (PPE)",
    "pdm1D": "Entropy of pitch periods. Evidence: 5/5. 85.6% accuracy as single feature (Little 2009) \u2014 the single best PD voice marker.",
    "pdm2": "Recurrence Period Density Entropy (RPDE)",
    "pdm2D": "Recurrence analysis of vocal fold vibration. Evidence: 5/5. Part of the PD quartet achieving 91.4% accuracy.",
    "pdm3": "Detrended Fluctuation Analysis (DFA)",
    "pdm3D": "Fractal scaling of noise in vocal fold vibration. Evidence: 5/5. Part of the PD quartet.",
    "pdm4": "Correlation Dimension (D2)",
    "pdm4D": "Phase space attractor complexity. Evidence: 3/5. Nonlinear dynamics measure of voice signal complexity.",
    "pdm5": "Vowel Space Area (VSA)",
    "pdm5D": "Area of F1/F2 vowel triangle. Evidence: 4/5. Progressive restriction correlates with axial gait dysfunction.",
    "pdm6": "Vowel Articulation Index (VAI)",
    "pdm6D": "Ratio-based articulatory precision measure. Evidence: 4/5. More sensitive than VSA to altered vowels.",
    "pdm7": "DDK Syllable Rate",
    "pdm7D": "/pa-ta-ka/ repetitions per second. Evidence: 5/5. 68.9% PD accuracy, 77.4% MSA accuracy (Harel 2004).",
    "pdm8": "DDK Regularity",
    "pdm8D": "Coefficient of variation of DDK intervals. Evidence: 4/5. Distinguishes tremor-dominant vs PIGD subtypes.",
    "pdm9": "Voice Onset Time (VOT)",
    "pdm9D": "Time from consonant release to voicing. Evidence: 3/5. Prolonged in PD \u2014 impaired articulatory timing.",
    "pdm10": "Spirantization Index",
    "pdm10D": "Consonant weakening measure. Evidence: 3/5. Cutting-edge Phonet DNN marker (Galaz 2023).",
    "pdm11": "Oral Festination",
    "pdm11D": "Involuntary progressive acceleration of speech. Evidence: 3/5. Correlates with gait festination in PD.",
    "pdm12": "Connected Speech Monopitch",
    "pdm12D": "F0 SD in connected speech. Evidence: 5/5. AUC 0.80 PD, AUC 0.65 prodromal RBD across 5 languages.",
    "scoringLabel": "Scoring Algorithm",
    "scoringTitle": "7-Step Evidence-Compiled V5",
    "scoringHighlight": "Scoring Pipeline",
    "scoringDesc": "Every score is computed deterministically from published research. No trained ML model, no black box \u2014 every number is traceable to its source study.",
    "score1Title": "Step 1: Baseline Computation",
    "score1Desc": "Establish personal baseline from 14\u201321 calibration sessions. Compute mean and standard deviation per indicator. High variance indicators (CV > 0.3) require extended calibration to 21 sessions.",
    "score2Title": "Step 2: Z-Score Normalization",
    "score2Desc": "Convert raw values to standardized drift scores: z = (value - baseline_mean) / baseline_std. Direction-normalized so negative always means decline. z < -0.5 = notable drift, z < -1.0 = significant, z < -1.5 = severe.",
    "score3Title": "Step 3: Domain Scoring",
    "score3Desc": "Weighted average of z-scores within each domain. Semantic (20%), Lexical (15%), Temporal (12%), Acoustic (12%), Syntactic (10%), Memory (10%), PD Motor (10%), Discourse (6%), Affective (5%).",
    "score4Title": "Step 4: Composite Score",
    "score4Desc": "Weighted combination of all 9 domain scores into a single metric. Alert thresholds: GREEN (\u2265 -0.5), YELLOW (\u2265 -1.0), ORANGE (\u2265 -1.5), RED (< -1.5).",
    "score5Title": "Step 5: Cascade Detection",
    "score5Desc": "Three cascade types: AD (fluency \u2192 semantic \u2192 syntactic \u2192 discourse collapse), PD (monopitch \u2192 phonatory \u2192 articulatory \u2192 prosodic collapse), Depression (affective shift \u2192 temporal retardation \u2192 engagement withdrawal). Order matters.",
    "score6Title": "Step 6: Sentinel Checking",
    "score6Desc": "Independent early warning flags per condition. AD sentinels: idea density, referential coherence, pronoun ratio, pause ratio, cued recall. Depression sentinels: self-pronouns, negative valence, variability, hedonic language. Must trigger \u22652 per condition.",
    "score7Title": "Step 7: Confounder Adjustment",
    "score7Desc": "Downweight scores when confounders reported. Illness/poor sleep: global 0.5\u00d7. Medication change: global 0.3\u00d7. Emotional distress: domain-specific weights (e.g., temporal 0.5\u00d7, memory 1.2\u00d7).",
    "diffLabel": "Differential Diagnosis",
    "diffTitle": "35-Rule Evidence-Based",
    "diffHighlight": "Differential Engine",
    "diffDesc": "The engine distinguishes 8 conditions using 35 decision rules. V5 includes rules for PD acoustic signature, MSA/PSP differentiation, acoustic depression, death/ruminative language, and prodromal PD detection.",
    "cond1": "Alzheimer's Disease",
    "cond1Desc": "AD cascade pattern + degraded referential coherence + poor cued recall (storage deficit) + declining idea density + within-clause pauses + monotonic decline trajectory.",
    "cond2": "Depression",
    "cond2Desc": "Preserved referential coherence + good cued recall (retrieval deficit) + elevated self-pronouns + negative valence + absolutist language + episodic fluctuation + anhedonia pattern.",
    "cond3": "Parkinson's Disease",
    "cond3Desc": "Temporal domain decline with preserved semantics + high pause ratio + reduced speech rate + pre-utterance pauses (motor initiation delay) + slow monotonic progression.",
    "cond4": "Medication Effects",
    "cond4Desc": "Acute cognitive drop coinciding with medication change. Expected recovery within 2\u20133 weeks. No cascade pattern. Context-flagged from session metadata.",
    "cond5": "Grief / Emotional Distress",
    "cond5Desc": "Depressive linguistic pattern with clear precipitating event. Self-limiting timeline. Context from session metadata overrides algorithmic scoring.",
    "cond6": "Normal Aging",
    "cond6Desc": "All domains > -0.3 z-score. Very slow lexical decline (~0.02/year). Stable syntax, stable memory. No cascade pattern. No sentinel triggers.",
    "cond7": "Multiple System Atrophy (MSA)",
    "cond7Desc": "PD-like pattern PLUS excessive F0 fluctuation, vocal tremor, strained voice quality. Hypokinetic-ataxic profile. DDK /pataka/ test achieves 77.4% MSA accuracy (Harel 2004).",
    "cond8": "Progressive Supranuclear Palsy (PSP)",
    "cond8Desc": "PD-like pattern PLUS stuttering-like behavior, severe articulatory decay, involuntary repetition. Hypokinetic-spastic profile. ~85% differentiation accuracy from PD.",
    "cascadeLabel": "Cascade Model",
    "cascadeTitle": "3 Cascade Types:",
    "cascadeHighlight": "AD, PD, Depression",
    "cascadeDesc": "V5 detects three distinct disease cascades. Each follows a predictable deterioration pattern \u2014 the order of domain involvement is diagnostically significant.",
    "adCascadeTitle": "Alzheimer\u2019s Disease Cascade",
    "stage0": "Stage 0: Pre-Symptomatic Fluency",
    "stage0Desc": "Subtle fluency micro-changes only. Temporal domain < -0.3 while lexical and semantic preserved. Validated by Young et al. 2024: tau correlation in cognitively normal adults.",
    "stage1": "Stage 1: Semantic Involvement",
    "stage1Desc": "Lexical and semantic domains declining. Word-finding difficulty, reduced idea density, topic drift. 12\u201324 months before diagnosis.",
    "stage2": "Stage 2: Syntactic Simplification",
    "stage2Desc": "Grammar complexity drops. Sentences shorten, subordination decreases. 6\u201318 months before diagnosis.",
    "stage3": "Stage 3: Discourse Collapse",
    "stage3Desc": "Multi-domain breakdown. Global coherence failure, narrative structure collapse. Around time of clinical diagnosis.",
    "pdCascadeTitle": "Parkinson\u2019s Disease Cascade",
    "pdStage0": "Stage 0: Prodromal",
    "pdStage0Desc": "Monopitch only, other features normal. AUC 0.65 for RBD (prodromal PD).",
    "pdStage1": "Stage 1: Phonatory",
    "pdStage1Desc": "HNR, jitter, shimmer degrading. Dysphonia dominant. Voice quality deterioration.",
    "pdStage2": "Stage 2: Articulatory",
    "pdStage2Desc": "VSA, DDK, VOT degrading. Imprecise consonants. Vowel space compression.",
    "pdStage3": "Stage 3: Prosodic Collapse",
    "pdStage3Desc": "Speech rate, pause patterns disrupted. Intelligibility loss. Festination may appear.",
    "depCascadeTitle": "Depression Cascade",
    "depStage0": "Stage 0: Affective Shift",
    "depStage0Desc": "Negative valence increase, self-referential pronouns elevated. Mood-driven language changes.",
    "depStage1": "Stage 1: Temporal Retardation",
    "depStage1Desc": "Speech rate slows, response latency increases. Psychomotor changes become measurable.",
    "depStage2": "Stage 2: Engagement Withdrawal",
    "depStage2Desc": "Reduced verbal output, hedonic language decline. Social and cognitive withdrawal.",
    "weeklyLabel": "Weekly Deep Analysis",
    "weeklyTitle": "Claude Opus 4.6",
    "weeklyHighlight": "Clinical Reasoning",
    "weeklyDesc": "Every week, Claude Opus 4.6 with extended thinking performs human-level clinical reasoning on the accumulated algorithmic data \u2014 NOT on raw conversation transcripts.",
    "weekly1": "Validate the algorithmic differential diagnosis \u2014 agree, disagree, or partially agree with the 35-rule system",
    "weekly2": "Discover micro-patterns the rules might miss \u2014 cross-domain interactions, subtle temporal trends",
    "weekly3": "Generate family report: 3\u20135 warm sentences in the patient's language, jargon-free",
    "weekly4": "Generate medical report: clinical terminology, scoring details, domain breakdowns",
    "weekly5": "Design next week's conversation probes \u2014 specific memory tests, topic selections based on current concerns",
    "weekly6": "Assess confidence: what is known, what is uncertain, and what additional data would help clarify",
    "microLabel": "Micro-Tasks",
    "microTitle": "4 Embedded",
    "microHighlight": "Clinical Tasks",
    "microDesc": "Structured clinical tasks embedded naturally in conversation. Scheduled based on patient risk profile. Maximum 2 per session to prevent fatigue.",
    "micro1Title": "Sustained Vowel /aaa/",
    "micro1Desc": "15-second sustained vowel for PD phonatory screening. Targets: PPE, RPDE, DFA, Jitter, Shimmer, HNR, CPP, D2. Evidence: Little 2009 \u2014 4 features achieve 91.4% PD classification. Frequency: Weekly when PD risk flagged.",
    "micro2Title": "DDK /pa-ta-ka/",
    "micro2Desc": "10-second diadochokinetic repetition for PD articulatory assessment. Targets: DDK rate, DDK regularity, VOT, Festination. Evidence: Harel 2004 \u2014 68.9% PD, 77.4% MSA accuracy. Frequency: Weekly when PD risk flagged.",
    "micro3Title": "Category Fluency \u2014 Animals",
    "micro3Desc": "60-second category naming task for AD and PD screening. Targets: Semantic fluency score, cluster analysis, switching rate. Standard neuropsychological screening tool. Frequency: Biweekly.",
    "micro4Title": "Depression Screening Question",
    "micro4Desc": "90-second open-ended response about recent mood. Targets: Negative valence, self-pronouns, hedonic language, death-words, ruminative patterns. Evidence: Grimm 2026 \u2014 single question achieves AUC 0.900 for PHQ-9. Frequency: Weekly for all patients.",
    "securityLabel": "Security Hardening",
    "securityTitle": "26 Vulnerabilities Audited,",
    "securityHighlight": "18 Fixed",
    "securityDesc": "V5 underwent a comprehensive security audit. All CRITICAL (5) and HIGH (6) issues are fixed. 7 MEDIUM fixed. 8 LOW deferred as acceptable risk.",
    "sec1Title": "Service-to-Service Auth",
    "sec1Desc": "CVF Engine only accepts requests via x-service-key header with crypto.timingSafeEqual() comparison. Minimum 32-character keys. Production fail-fast if unconfigured.",
    "sec2Title": "Input Validation",
    "sec2Desc": "Strict Fastify JSON Schema on all endpoints. PatientId regex-validated, transcript items capped at 10KB, audio limited to 10MB, enums for format/language.",
    "sec3Title": "Command Injection Prevention",
    "sec3Desc": "Python acoustic pipeline uses execFile with array args (no shell). Strict enum validation on task types and gender before execution. No user input reaches shell.",
    "sec4Title": "LLM Prompt Injection Defense",
    "sec4Desc": "Three-layer defense: system prompt guardrail marking transcript as raw data, XML boundary tags, and post-extraction anomaly detection rejecting >80% identical indicator values.",
    "sec5Title": "Path Traversal Prevention",
    "sec5Desc": "All patient IDs validated against /^[a-zA-Z0-9_-]{1,64}$/ regex. File operations use path.basename() sanitization. No user input in file paths.",
    "sec6Title": "Numeric Safety + Data Privacy",
    "sec6Desc": "NaN/Infinity propagation prevented via safeDiv() across all arithmetic. PHI never logged \u2014 SHA-256 hashed patient IDs. Session IDs use crypto.randomUUID().",
    "evidenceLabel": "Evidence Base",
    "evidenceTitle": "Grounded in 80",
    "evidenceHighlight": "Research Papers",
    "evidenceDesc": "V5 is compiled from 80 research papers (74 PDFs + 6 summaries) across Alzheimer\u2019s (39), Depression (15), and Parkinson\u2019s (26). Key benchmark accuracies:",
    "evidence1": "Little 2009 \u2014 PD detection: 91.4% accuracy with HNR+RPDE+DFA+PPE quartet (kernel SVM). PPE alone achieves 85.6%.",
    "evidence2": "Martinc 2021 \u2014 AD detection: 93.75% accuracy with ADR + text ensemble. Multimodal (text + audio) significantly outperforms text-only.",
    "evidence3": "Le 2026 \u2014 Cross-cultural depression: AUC 0.934 with 12 acoustic features (XGBoost). MFCC-2 is highest SHAP feature.",
    "evidence4": "Grimm 2026 \u2014 Single depression question: AUC 0.900 for PHQ-9 using MPNet + HuBERT multimodal analysis.",
    "evidence5": "Snowdon 1996 (Nun Study) \u2014 Low idea density at age 22 predicted AD 60+ years later. Strongest long-range predictor ever documented.",
    "evidence6": "Eyigoz 2020 (Framingham) \u2014 Embedding coherence predicts AD 7.6 years pre-diagnosis (AUC 0.74). Outperforms APOE genotype.",
    "evidence7": "Fraser 2015 \u2014 81.92% text-only AD accuracy from 370 features. Foundation for V5\u2019s expanded text pipeline.",
    "evidence8": "Harel 2004 \u2014 DDK /pataka/ achieves 68.9% PD accuracy and 77.4% MSA differentiation. Key articulatory task.",
    "evidence9": "Dehghanghanatkaman 2026 \u2014 Voice features predict UPDRS motor scores with R\u00b2 = 0.99. More accurate than many clinical assessments.",
    "evidence10": "Young 2024 \u2014 Speech fluency correlated with tau burden in 238 cognitively normal adults. Speech precedes memory changes.",
    "backToHome": "Back to Home"
  }
}
